{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "empirical-defeat",
   "metadata": {},
   "source": [
    "## Data exploration ##\n",
    "\n",
    "Load the data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "considered-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "trainfile = 'train-images-idx3-ubyte'\n",
    "trainfilelabels = 'train-labels-idx1-ubyte'\n",
    "testfile = 't10k-images-idx3-ubyte'\n",
    "testfilelabels = 't10k-labels-idx1-ubyte'\n",
    "x_train = idx2numpy.convert_from_file(trainfile)\n",
    "y_train = idx2numpy.convert_from_file(trainfilelabels)\n",
    "x_test = idx2numpy.convert_from_file(testfile)\n",
    "y_test = idx2numpy.convert_from_file(testfilelabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-devil",
   "metadata": {},
   "source": [
    "#### Inspect the datasets ####\n",
    "In the previous lab we had to split the data into train and test ourselves. Notice that in this lab the split has already been done for us.\n",
    "x_train are the images. You could see every pixel as an input feature. y_train are the labels of the image. This is a one-dimensional array with the digits as assigned by a person (0 to 9).\n",
    "Equally, x_train and y_train are the images and corresponding labels for the test set. \n",
    "\n",
    "#### Verify the data ####\n",
    "How many images do we have for training, and what is the size of each image?\n",
    "The following shows that the training data set has 60000 images. The other values indicate the dimensions of the image: 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "complex-ribbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-grocery",
   "metadata": {},
   "source": [
    "What is the shape of the labels for training?\n",
    "The following shows that we have a list of 60000 entries. Each entry indicates the digit for the image (a value from 0 to 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "given-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-position",
   "metadata": {},
   "source": [
    "Let's do the same for the test images.\n",
    "This will tell us that there are 10000 images for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "unlikely-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-munich",
   "metadata": {},
   "source": [
    "And let's doublecheck the labels of the test images.\n",
    "This will show that the images are labeled with the corresponding digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "copyrighted-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-homework",
   "metadata": {},
   "source": [
    "How does one particular image actually look like?\n",
    "Let's display one of the training images at random, in this case the one with index 5 (of 60000).\n",
    "You can more or less see a shape of a digit show up. We'll show it as an actual image a bit later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "governing-flexibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  13,  25, 100, 122,   7,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         33, 151, 208, 252, 252, 252, 146,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 152,\n",
       "        244, 252, 253, 224, 211, 252, 232,  40,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  15, 152, 239, 252,\n",
       "        252, 252, 216,  31,  37, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 252,\n",
       "        252, 217,  29,   0,  37, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 181, 252, 252, 220,\n",
       "        167,  30,   0,   0,  77, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  26, 128,  58,  22,\n",
       "          0,   0,   0,   0, 100, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 157, 252, 252,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        110, 121, 122, 121, 202, 252, 194,   3,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  53, 179,\n",
       "        253, 253, 255, 253, 253, 228,  35,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   5,  54, 227, 252, 243,\n",
       "        228, 170, 242, 252, 252, 231, 117,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   6,  78, 252, 252, 125,  59,\n",
       "          0,  18, 208, 252, 252, 252, 252,  87,   7,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   5, 135, 252, 252, 180,  16,   0,\n",
       "         21, 203, 253, 247, 129, 173, 252, 252, 184,  66,  49,  49,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3, 136, 252, 241, 106,  17,   0,  53,\n",
       "        200, 252, 216,  65,   0,  14,  72, 163, 241, 252, 252, 223,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 105, 252, 242,  88,  18,  73, 170, 244,\n",
       "        252, 126,  29,   0,   0,   0,   0,   0,  89, 180, 180,  37,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 231, 252, 245, 205, 216, 252, 252, 252,\n",
       "        124,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 207, 252, 252, 252, 252, 178, 116,  36,\n",
       "          4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  13,  93, 143, 121,  23,   6,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-massage",
   "metadata": {},
   "source": [
    "What is the label for this particular image?\n",
    "Let's show the label by accessing the y_train with the same index (5).\n",
    "According to the labels, this is an image of the digit 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "removable-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-excerpt",
   "metadata": {},
   "source": [
    "Display the data as an image\n",
    "Let's verify this by displaying the data as an image. We will use the matplotlib library to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fourth-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1ca496d160>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[5], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-commerce",
   "metadata": {},
   "source": [
    "## Data preparation ##\n",
    "\n",
    "The Neural Network that we want to build will have an input layer of 784 neurons. See also the architecture picture above. Each of the neurons will represent one pixel in the input image.\n",
    "There are two issues that we have to address:\n",
    "The shape: We must convert the 2D shape of 28x28x1 pixels into a 1D array of 784 elements.\n",
    "The values: Our input neurons expect values between 0.0 and 1.0, however our actual input values are currently 0 to 255. We must scale these values as well.\n",
    "\n",
    "### Flatten the 28x28 array ###\n",
    "Flatten the array of each image into a 784 array. Do this for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "satisfactory-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-monster",
   "metadata": {},
   "source": [
    "Check the results\n",
    "Let's check that this conversion was successful by checking the new shape of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "negative-sound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-horse",
   "metadata": {},
   "source": [
    "Scale the values of the pixels from 0-255 to 0.0-1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "moved-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-grenada",
   "metadata": {},
   "source": [
    "Check the results\n",
    "Let's check the result by again displaying our example digit at index 5. You will see that there are no rows anymore in the array (it's 1D now), and that the values are between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "spiritual-radical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05098039, 0.09803922, 0.39215687, 0.47843137, 0.02745098,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12941177, 0.5921569 , 0.8156863 , 0.9882353 ,\n",
       "       0.9882353 , 0.9882353 , 0.57254905, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15686275, 0.59607846, 0.95686275,\n",
       "       0.9882353 , 0.99215686, 0.8784314 , 0.827451  , 0.9882353 ,\n",
       "       0.9098039 , 0.15686275, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05882353, 0.59607846,\n",
       "       0.9372549 , 0.9882353 , 0.9882353 , 0.9882353 , 0.84705883,\n",
       "       0.12156863, 0.14509805, 0.9882353 , 0.9882353 , 0.23529412,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3764706 , 0.9882353 , 0.9882353 , 0.9882353 ,\n",
       "       0.9882353 , 0.8509804 , 0.11372549, 0.        , 0.14509805,\n",
       "       0.9882353 , 0.9882353 , 0.23529412, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.70980394,\n",
       "       0.9882353 , 0.9882353 , 0.8627451 , 0.654902  , 0.11764706,\n",
       "       0.        , 0.        , 0.3019608 , 0.9882353 , 0.9882353 ,\n",
       "       0.23529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10196079, 0.5019608 , 0.22745098,\n",
       "       0.08627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39215687, 0.9882353 , 0.9882353 , 0.23529412, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6156863 , 0.9882353 ,\n",
       "       0.9882353 , 0.23529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.43137255, 0.4745098 , 0.47843137,\n",
       "       0.4745098 , 0.7921569 , 0.9882353 , 0.7607843 , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03921569, 0.20784314, 0.7019608 ,\n",
       "       0.99215686, 0.99215686, 1.        , 0.99215686, 0.99215686,\n",
       "       0.89411765, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01960784, 0.21176471,\n",
       "       0.8901961 , 0.9882353 , 0.9529412 , 0.89411765, 0.6666667 ,\n",
       "       0.9490196 , 0.9882353 , 0.9882353 , 0.90588236, 0.45882353,\n",
       "       0.02352941, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02352941, 0.30588236, 0.9882353 , 0.9882353 , 0.49019608,\n",
       "       0.23137255, 0.        , 0.07058824, 0.8156863 , 0.9882353 ,\n",
       "       0.9882353 , 0.9882353 , 0.9882353 , 0.34117648, 0.02745098,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01960784, 0.5294118 , 0.9882353 ,\n",
       "       0.9882353 , 0.7058824 , 0.0627451 , 0.        , 0.08235294,\n",
       "       0.79607844, 0.99215686, 0.96862745, 0.5058824 , 0.6784314 ,\n",
       "       0.9882353 , 0.9882353 , 0.72156864, 0.25882354, 0.19215687,\n",
       "       0.19215687, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.53333336, 0.9882353 , 0.94509804, 0.41568628, 0.06666667,\n",
       "       0.        , 0.20784314, 0.78431374, 0.9882353 , 0.84705883,\n",
       "       0.25490198, 0.        , 0.05490196, 0.28235295, 0.6392157 ,\n",
       "       0.94509804, 0.9882353 , 0.9882353 , 0.8745098 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.4117647 , 0.9882353 , 0.9490196 ,\n",
       "       0.34509805, 0.07058824, 0.28627452, 0.6666667 , 0.95686275,\n",
       "       0.9882353 , 0.49411765, 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34901962, 0.7058824 ,\n",
       "       0.7058824 , 0.14509805, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.90588236, 0.9882353 , 0.9607843 , 0.8039216 , 0.84705883,\n",
       "       0.9882353 , 0.9882353 , 0.9882353 , 0.4862745 , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.8117647 , 0.9882353 ,\n",
       "       0.9882353 , 0.9882353 , 0.9882353 , 0.69803923, 0.45490196,\n",
       "       0.14117648, 0.01568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05098039, 0.3647059 , 0.56078434, 0.4745098 ,\n",
       "       0.09019608, 0.02352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-budapest",
   "metadata": {},
   "source": [
    "## Model build and training ##\n",
    "\n",
    "Doublecheck the shapes\n",
    "Let's doublecheck the shapes of the input data before we start the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "smooth-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "x_train shape: (60000,)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_train shape:', y_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-obligation",
   "metadata": {},
   "source": [
    "#### Construct the model ####\n",
    "Our data is ready to go. Now it's time to build the neural network. Remember, we will build an input layer of 784 neurons, then two hidden layers of 16 neurons each, and finally an output layer of 10 neurons (one for each digit). If this is unclear, please review the architecture at the start of the lab. We are using the Tensorflow and Keras open source libraries for this.\n",
    "\n",
    "Notice that there is no clear methodology that can tell you from the beggining what the right size and number of hidden layers would be required. To be able to determine this parameters you would need to \"debug\" the neural network. Change the number of hidden layers or the size of the neurons and monitor if the loss gets lower and the accuracy increases. Later validate this on the test set.\n",
    "Notice how in the first model.add we have to specify both the input shape (784 neurons) and the first hidden layer (16 neurons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "prepared-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(784, ), activation=tf.nn.relu))\n",
    "model.add(Dense(16, activation=tf.nn.relu))\n",
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-recorder",
   "metadata": {},
   "source": [
    "#### Train the model ####\n",
    "\n",
    "At this point the initial architecture of our Neural Network is ready. It has random weights to start with. Next, we will train the model to optimize the weights.\n",
    "Depending on the shape you are running the notebook on, this can take a few minutes.\n",
    "Notice that the input for the model training is the training images (x_train) and the training labels (y_train). We have chosen 10 epochs. This means the neural network would run through the entire dataset 10 times.\n",
    "\n",
    "'loss' specifies the loss or also called the objective function. It calculates how far off the neural network's predictions are. The results are used to adjust the weights to minimize the loss.\n",
    "\n",
    "'optimizer' is a function used to minimize the loss. To do so we need to adjust the waits in the forward and the backpropagation. The optimizer is the function that would be used in that process.\n",
    "\n",
    "'metrics' is a function that is used to judge the performance of the model. You can specify one or more metrics. It is similar to the loss function but the result is not used when training the model. You could use as metric any of the loss functions available in Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "pharmaceutical-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4330 - accuracy: 0.8733\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2364 - accuracy: 0.9321\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2009 - accuracy: 0.9415\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1803 - accuracy: 0.9466\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1643 - accuracy: 0.9512\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1546 - accuracy: 0.9541\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1457 - accuracy: 0.9567\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1380 - accuracy: 0.9581\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1318 - accuracy: 0.9607\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1270 - accuracy: 0.9613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ca4cc72e8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-premises",
   "metadata": {},
   "source": [
    "## Check model accuracy ##\n",
    "\n",
    "You should see an accuracy of around 96%. This is the accuracy on the data in the training set. However, as you know by now, it's important to verify the accuracy of the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-maria",
   "metadata": {},
   "source": [
    "#### Visual verification of the model by predicting an example ####\n",
    "First of all, let's check the performance intuitively through a visualization. Let's take an example image from the test set and check if the model is able to classify it correctly. We'll take a random index of 99.\n",
    "You will see this is a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "scientific-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c9566e400>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOF0lEQVR4nO3dbchc9ZnH8d/PpD7FqtHchKBiasibGFDLEBYrxbVZn14YfSNViQpqKqixEHSDKzSIiOhaqbiUpOtDXF2lYGMUZbeuFMQ3xVGixujeakzQGM0dQ6wlUdf02hf3SbmNM2fuzDnzkFzfD9zMzLnmzLk8+MuZOf8z83dECMDB75BBNwCgPwg7kARhB5Ig7EAShB1IYmo/NzZjxoyYPXt2PzcJpLJp0yZt377drWqVwm77fEm/kTRF0r9HxN1lz589e7aazWaVTQIo0Wg02ta6fhtve4qkf5N0gaR5ki6zPa/b1wPQW1U+sy+Q9H5EbIyIbyQ9JWlRPW0BqFuVsJ8g6aMJjz8uln2H7SW2m7abY2NjFTYHoIqen42PiFUR0YiIxsjISK83B6CNKmHfIumkCY9PLJYBGEJVwv6qpLm2f2T7UEk/l/RsPW0BqFvXQ28R8a3tGyX9t8aH3h6OiLdr6wxArSqNs0fEC5JeqKkXAD3E5bJAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJCpN2Wx7k6QvJe2R9G1ENOpoCkD9KoW98I8Rsb2G1wHQQ7yNB5KoGvaQ9Efbr9le0uoJtpfYbtpujo2NVdwcgG5VDftZEfFjSRdIusH2T/d9QkSsiohGRDRGRkYqbg5AtyqFPSK2FLfbJK2RtKCOpgDUr+uw255m+4d770s6V9L6uhoDUK8qZ+NnSlpje+/r/GdE/FctXSUTEaX1zz//vLS+du3atrWlS5eWrrtr167SeifTpk0rrT/wwANta1deeWXpulOn1jFYhL263psRsVHSaTX2AqCHGHoDkiDsQBKEHUiCsANJEHYgCcY2+mDjxo2l9TvvvLO0vnr16jrb+Y5DDqn27/3u3btL69ddd13b2ujoaOm6d911V2m9au/ZsLeAJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2WvQ6Suqt9xyS2n9mWeeqbGb/TNlypRK9W+++abrbd97772l9TPPPLO0ftFFF3W97Yw4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzT1LZWPrKlStL1606jn7EEUeU1ufPn9+2tmzZstJ1zznnnNL68ccfX1pfvnx5ab3TWHqZJ554orR+3nnnldYPO+ywrrd9MOLIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJuNN3sevUaDSi2Wz2bXt12rNnT9vaoYceWum1O31nvNPvyt96662Vtl/FV199VVqfN29e29rmzZsrbfuxxx4rrV9xxRWVXv9A1Gg01Gw23arW8chu+2Hb22yvn7DsONsv2n6vuJ1eZ8MA6jeZt/GPSjp/n2XLJb0UEXMlvVQ8BjDEOoY9Il6WtGOfxYsk7Z2TaLWki+ttC0Dduj1BNzMithb3P5U0s90TbS+x3bTdHBsb63JzAKqqfDY+xs/wtT3LFxGrIqIREY2RkZGqmwPQpW7D/pntWZJU3G6rryUAvdBt2J+VdFVx/ypJa+tpB0CvdPw+u+0nJZ0taYbtjyX9StLdkn5v+xpJmyVd2ssmD3Z33HFHaX2Q4+idHH744aX1p59+um2t0WhU2nan+dsXLVrUtnbUUUdV2vaBqGPYI+KyNqWf1dwLgB7iclkgCcIOJEHYgSQIO5AEYQeS4KekJ2n9+vWdn9TG9OnlXwq86aabun7tQfv6669L65dffnnPtv3uu++W1u+55562tU7DnQcjjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7JO0YcOGrtedOrV8N9stf/l3KOzcubO0fvXVV5fWR0dH62tmPz366KNtaytWrChd95BDDr7j4MH3XwSgJcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9kmq8rPHnaa96jT18PXXX9/1tjtNyb19+/bS+u23315af+655/a7p3659NL2v3A+zNc29ApHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2STrllFN69tqPPPJIaX3u3Lml9Tlz5rStPfjgg6Xr3n///aX1YXbMMceU1hcvXty2xjh7C7Yftr3N9voJy1bY3mJ7XfF3YW/bBFDVZN7GPyrp/BbL74+I04u/F+ptC0DdOoY9Il6WtKMPvQDooSon6G60/WbxNr/tZGa2l9hu2m52ukYcQO90G/bfSpoj6XRJWyXd1+6JEbEqIhoR0RgZGelycwCq6irsEfFZROyJiL9J+p2kBfW2BaBuXYXd9qwJDy+R1P18xgD6ouM4u+0nJZ0taYbtjyX9StLZtk+XFJI2SfpF71ocDmW/I37ffW0/xUiSli1bVlpvNpul9XPPPbe0PsxOO+20trU33nij0msvXLiw621n1DHsEXFZi8UP9aAXAD3E5bJAEoQdSIKwA0kQdiAJwg4kwVdcJ6nsK5FLly4tXXf+/Pml9aeeeqpSfffu3W1rnb7KOXPmzNL6ggXl10s9/vjjpfWPPvqobe3UU08tXbeTm2++udL62XBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk3GlK3zo1Go3o9HVOfN/mzZtL61u2bGlbmzq1/FKKTuPoVe3atatt7Ywzzihd94svviitj46OltaPPvro0vrBqNFoqNlstry4giM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB99kPACeffHKl+iCVXcexZ8+e0nWPPPLI0nrGcfQqOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6OnPvjgg7a1Dz/8sHTdlStX1t1Oah2P7LZPsv0n2xtsv2375mL5cbZftP1ecTu99+0C6NZk3sZ/K2lZRMyT9A+SbrA9T9JySS9FxFxJLxWPAQypjmGPiK0R8Xpx/0tJ70g6QdIiSauLp62WdHGPegRQg/06QWd7tqQzJP1Z0syI2FqUPpXUctIw20tsN203x8bGqvQKoIJJh932UZKelvTLiPjLxFqMf9uh5TceImJVRDQiojEyMlKpWQDdm1TYbf9A40F/IiL+UCz+zPasoj5L0rbetAigDh2H3jw+5+9Dkt6JiF9PKD0r6SpJdxe3a3vSIQ5oVYbPnn/++dL6tdde2/VrZzSZcfafSFos6S3b64plt2k85L+3fY2kzZIu7UmHAGrRMewR8Yqklj86L+ln9bYDoFe4XBZIgrADSRB2IAnCDiRB2IEk+IorhtYrr7xSWt+5c2dp/dhjj62vmYMAR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxdgytHTt2lNZHR0dL6wsWLKiznQMeR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYjLzs58k6TFJMyWFpFUR8RvbKyRdJ2mseOptEfFCrxrFgemSSy5pW1uzZk3purt27Sqtn3jiiV31lNVkfrziW0nLIuJ12z+U9JrtF4va/RHxr71rD0BdJjM/+1ZJW4v7X9p+R9IJvW4MQL326zO77dmSzpD052LRjbbftP2w7elt1lliu2m7OTY21uopAPpg0mG3fZSkpyX9MiL+Ium3kuZIOl3jR/77Wq0XEasiohERjZGRkeodA+jKpMJu+wcaD/oTEfEHSYqIzyJiT0T8TdLvJPHrfsAQ6xh225b0kKR3IuLXE5bPmvC0SyStr789AHWZzNn4n0haLOkt2+uKZbdJusz26Rofjtsk6Rc96A8HuIULF7atffLJJ33sBJM5G/+KJLcoMaYOHEC4gg5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5CEI6J/G7PHJG2esGiGpO19a2D/DGtvw9qXRG/dqrO3kyOi5e+/9TXs39u43YyIxsAaKDGsvQ1rXxK9datfvfE2HkiCsANJDDrsqwa8/TLD2tuw9iXRW7f60ttAP7MD6J9BH9kB9AlhB5IYSNhtn2/7f22/b3v5IHpox/Ym22/ZXme7OeBeHra9zfb6CcuOs/2i7feK25Zz7A2otxW2txT7bp3tCwfU20m2/2R7g+23bd9cLB/ovivpqy/7re+f2W1PkTQq6Z8kfSzpVUmXRcSGvjbShu1NkhoRMfALMGz/VNJfJT0WEfOLZfdI2hERdxf/UE6PiH8ekt5WSPrroKfxLmYrmjVxmnFJF0u6WgPcdyV9Xao+7LdBHNkXSHo/IjZGxDeSnpK0aAB9DL2IeFnSjn0WL5K0uri/WuP/s/Rdm96GQkRsjYjXi/tfSto7zfhA911JX30xiLCfIOmjCY8/1nDN9x6S/mj7NdtLBt1MCzMjYmtx/1NJMwfZTAsdp/Hup32mGR+afdfN9OdVcYLu+86KiB9LukDSDcXb1aEU45/BhmnsdFLTePdLi2nG/26Q+67b6c+rGkTYt0g6acLjE4tlQyEithS32ySt0fBNRf3Z3hl0i9ttA+7n74ZpGu9W04xrCPbdIKc/H0TYX5U01/aPbB8q6eeSnh1AH99je1px4kS2p0k6V8M3FfWzkq4q7l8lae0Ae/mOYZnGu9004xrwvhv49OcR0fc/SRdq/Iz8B5L+ZRA9tOnrFElvFH9vD7o3SU9q/G3d/2n83MY1ko6X9JKk9yT9j6Tjhqi3/5D0lqQ3NR6sWQPq7SyNv0V/U9K64u/CQe+7kr76st+4XBZIghN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wMCpzhsSYY7BAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[99].reshape(28, 28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-circulation",
   "metadata": {},
   "source": [
    "What is the official label for this digit?\n",
    "You will see this is labelled as a 9 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "permanent-month",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-bread",
   "metadata": {},
   "source": [
    "Is our model able to correctly classify it as a 9?\n",
    "The argmax function returns the output neuron that has the highest value. In this case this correctly predicts a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "opponent-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test[99].reshape(1,784))\n",
    "print(predict.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-summer",
   "metadata": {},
   "source": [
    "#### Numerical verification of the model ####\n",
    "\n",
    "We can use model.evaluate to calculate the accuracy of prediction on the entire testset. This will run the prediction on the 10000 images in the testset and compare the predicted digits with the actual labels, and calculate an accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "round-courtesy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16676022112369537, 0.9510999917984009]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-buying",
   "metadata": {},
   "source": [
    "You should see an accuracy on unseen data of about 95%. This is the actual accuracy of the model. In other words, the model is able to interpret an image of a digit and correctly classify it in 95% of the cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlcpuv1]",
   "language": "python",
   "name": "conda-env-mlcpuv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
